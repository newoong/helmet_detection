{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3da600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#yolo model load\n",
    "yolonet=cv2.dnn.readNet('yoloface-master/model-weights/yolov3-wider_16000.weights','yoloface-master/cfg/yolov3-face.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a9835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "googlenet=tf.keras.models.load_model('cat_soft_bi.h5')\n",
    "#googlenet model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d8ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = yolonet.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in yolonet.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc1f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "#실행하는 하드웨어마다 카메라 size가 다르므로 설정해줌\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "channel=3\n",
    "\n",
    "#bounding box color임의 지정 (2,3)으로 2가지 색깔 가져옴(helmet_on,helmet_off)\n",
    "colors=np.random.uniform(0,255,size=(2,3)) \n",
    "\n",
    "on_col=colors[0] #helmet on color\n",
    "off_col=colors[1] #helmet off color\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "print(width,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ca5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # reading the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # preprocessing for yolo\n",
    "    blob=cv2.dnn.blobFromImage(frame,0.00392,(416,416),(0,0,0),True,crop=False) #yolo 적용을 위한 전처리\n",
    "    yolonet.setInput(blob)\n",
    "    outs=yolonet.forward(output_layers)\n",
    "    \n",
    "    boxes=[]\n",
    "    confidences=[]\n",
    "    class_ids=[]\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            confidence=detection[5] #class face로 1개이므로 [5:]가 아닌 5만 보면 됨\n",
    "            if confidence>0.1: #정확도를 위해서 올릴 수 있어\n",
    "                center_x=int(detection[0]*width)\n",
    "                center_y=int(detection[1]*height)\n",
    "                w=int(detection[2]*width)\n",
    "                h=int(detection[3]*height)\n",
    "\n",
    "                x=int(center_x-w/2)\n",
    "                y=int(center_y-h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h]) #후보군들\n",
    "                confidences.append(float(confidence))\n",
    "    \n",
    "    indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.1,0.4) #boxes로 선정된 것 중 Confidence가 threshold이상인 것들만 indexes에\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x,y,w,h=boxes[i]\n",
    "            #helmet size까지 고려하여 bbox size 수정 & Frame 밖으로 나가서 오류나지 않도록 min,max\n",
    "            x_1=np.max([0,x-int(0.4*w)])\n",
    "            y_1=np.max([0,y-int(0.7*h)])\n",
    "            x_2=np.min([width,x+int(1.4*w)])\n",
    "            y_2=np.min([height,y+int(1.2*h)])\n",
    "            croped=frame[y_1:y_2,x_1:x_2]\n",
    "            croped=cv2.resize(croped,(224,224))\n",
    "            croped=croped.reshape(1,224,224,3)\n",
    "            prob=model.predict(croped,verbose=False)[0] #return 3개(output, aux1, aux2)\n",
    "            pred=np.argmax(prob)\n",
    "            if pred==0: #pred==0 : 헬멧착용\n",
    "                cv2.rectangle(frame,(x_1,y_1),(x_2,y_2),on_col,2)\n",
    "                cv2.putText(frame,'on',(x_1,y_1+5),font,1,on_col,2)\n",
    "            else: #pred==1 : 헬멧미착용\n",
    "                cv2.rectangle(frame,(x_1,y_1),(x_2,y_2),off_col,2)\n",
    "                cv2.putText(frame,'off',(x_1,y_1+5),font,1,off_col,2)\n",
    "            \n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "        \n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        # breaking the loop if the user types q\n",
    "        # note that the video window must be highlighted!\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
